"""
ANALYSEUR D'ORIENTATION PROFESSIONNELLE
Version ultra-optimis√©e, indestructible et monolithique
Avec am√©liorations 2025 (suggestions m√©tiers + export PDF + analyses avanc√©es)
"""
import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import re
import time
import json
import unicodedata
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from fpdf import FPDF
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import io
import base64

# --- CONFIGURATION CENTRALE ---
st.set_page_config(page_title="Analyseur d'Orientation", page_icon="‚ö°", layout="wide")

# Chargement brutal de l'API key
load_dotenv(override=True)
API_KEY = os.getenv("OPENROUTER_API_KEY", "")

# Constantes du projet
HISTORY_FILE = "orientation_history.json"

# --- FONCTIONS ESSENTIELLES ---

def sanitize_text(text):
    """Nettoyage brutal du texte"""
    if not isinstance(text, str):
        return str(text) if text is not None else "Non specifie"
    return ''.join(c for c in unicodedata.normalize('NFD', text) if not unicodedata.combining(c))

def save_api_key(api_key):
    """Enregistrement avec activation imm√©diate"""
    try:
        with open(".env", "w") as file:
            file.write(f'OPENROUTER_API_KEY="{api_key}"')
        os.environ["OPENROUTER_API_KEY"] = api_key
        return True, "Cl√© API enregistr√©e avec succ√®s"
    except Exception as e:
        return False, f"Erreur d'enregistrement: {str(e)}"

def call_api(prompt, max_retries=3):
    """Appel API blind√© contre tout √©chec"""
    global API_KEY

    # V√©rification cl√© API
    if not API_KEY:
        return {"error": "Cl√© API manquante ou invalide"}

    # Initialisation client
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=API_KEY,
        timeout=30.0
    )

    # Tentatives multiples avec backoff exponentiel
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "https://orientation-analyzer.com",
                    "X-Title": "Analyseur d'Orientation Pro"
                },
                model="deepseek/deepseek-chat-v3-0324",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=500
            )

            # V√©rification implacable
            if not response or not hasattr(response, 'choices') or len(response.choices) == 0:
                raise ValueError("R√©ponse API malform√©e")

            content = response.choices[0].message.content
            if not content:
                raise ValueError("Contenu vide")

            return {"success": True, "content": content}

        except Exception as e:
            if attempt == max_retries - 1:
                return {"error": str(e)}
            time.sleep(2 ** attempt)  # backoff exponentiel

def extract_score(analysis_text):
    """Extraction du score de coh√©rence"""
    if not isinstance(analysis_text, str):
        return None

    if "error" in analysis_text.lower():
        return None

    patterns = [
        r"NIVEAU DE COH√âRENCE:?\s*\[?(\d+)[/\]]",
        r"NIVEAU DE COH√âRENCE:?\s*(\d+)",
        r"coh√©rence:?\s*(\d+)",
        r"score:?\s*(\d+)",
        r"(\d+)/10"
    ]

    for pattern in patterns:
        matches = re.search(pattern, analysis_text, re.IGNORECASE)
        if matches:
            score = int(matches.group(1))
            return max(0, min(score, 10))

    return None

def extract_recommended_jobs(analysis_text):
    """Extraction des m√©tiers recommand√©s"""
    if not isinstance(analysis_text, str):
        return []

    # Recherche de la section des m√©tiers recommand√©s
    pattern = r"M√âTIERS RECOMMAND√âS:(.+?)(?:\n\n|\Z)"
    match = re.search(pattern, analysis_text, re.DOTALL | re.IGNORECASE)

    if not match:
        return []

    # Extraction des m√©tiers list√©s avec tirets
    jobs_section = match.group(1)
    jobs = re.findall(r"[-‚Ä¢*]\s*(.+?)(?:\n|$)", jobs_section)

    # Nettoyage des r√©sultats
    return [job.strip() for job in jobs if job.strip()]

def analyze_career(student_data):
    """Analyse d'orientation am√©lior√©e avec suggestions de m√©tiers"""
    # V√©rification des donn√©es
    filiere = student_data.get('filiere', '')
    carriere = student_data.get('carriere', '')

    if len(filiere.strip()) < 2 or len(carriere.strip()) < 3:
        return {"error": "Donn√©es insuffisantes", "score": None}

    prompt = f"""
    ANALYSE D'ORIENTATION PROFESSIONNELLE - FORMAT STRICTEMENT OBLIGATOIRE
    
    DONN√âES √âTUDIANT:
    - Fili√®re actuelle: {filiere}
    - Carri√®re vis√©e: {carriere}
    
    FOURNIR OBLIGATOIREMENT CES QUATRE SECTIONS:
    1. NIVEAU DE COH√âRENCE: [0-10]
    Justification factuelle:
    
    2. ERREURS CRITIQUES:
    - Comp√©tence manquante 1:
    - Comp√©tence manquante 2:
    
    3. RECOMMANDATIONS:
    - Action correctrice 1:
    - Action correctrice 2:
    
    4. M√âTIERS RECOMMAND√âS:
    - M√©tier alternatif 1:
    - M√©tier alternatif 2:
    
    INSTRUCTIONS: 
    - Attribuez un score de coh√©rence (et non d'incoh√©rence) de 0 √† 10 (10 √©tant parfait)
    - Les scores √©lev√©s indiquent une bonne correspondance fili√®re/carri√®re
    - Sugg√©rez 2 m√©tiers r√©alistes et pr√©cis qui exploitent les comp√©tences de la fili√®re
    - Soyez brutalement honn√™te dans votre analyse
    """

    # Appel API prot√©g√©
    response = call_api(prompt)

    if "error" in response:
        return {"error": response["error"], "score": None}

    # Extraction de l'analyse
    analysis = response["content"]
    score = extract_score(analysis)
    recommended_jobs = extract_recommended_jobs(analysis)

    return {
        "analysis": analysis,
        "score": score,
        "recommended_jobs": recommended_jobs
    }

def load_file(file):
    """Chargement blind√© des donn√©es"""
    try:
        if file.name.endswith('.csv'):
            for encoding in ['utf-8', 'latin1', 'cp1252']:
                try:
                    file.seek(0)
                    return pd.read_csv(file, encoding=encoding), None
                except:
                    continue
            return None, "Impossible de d√©coder le CSV"
        elif file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(file), None
        else:
            return None, "Format non support√©"
    except Exception as e:
        return None, str(e)

def save_to_history(results):
    """Sauvegarde indestructible des r√©sultats"""
    try:
        # Pr√©paration des donn√©es
        history_data = []
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                    history_data = json.load(f)
            except Exception:
                history_data = []  # Reset en cas de corruption

        # Garantir que c'est une liste
        if not isinstance(history_data, list):
            history_data = []

        # Ajout des nouveaux r√©sultats
        timestamp = datetime.now().isoformat()
        for result in results:
            if isinstance(result, dict) and "analysis" in result and "error" not in result.get("analysis", ""):
                entry = {
                    "timestamp": timestamp,
                    "nom": result.get("Nom", "Anonyme"),
                    "filiere": result.get("Fili√®re", "Non sp√©cifi√©e"),
                    "carriere": result.get("Carri√®re", "Non sp√©cifi√©e"),
                    "score": result.get("score"),
                    "analysis": result.get("analysis", ""),
                    "recommended_jobs": result.get("recommended_jobs", [])
                }
                history_data.append(entry)

        # Sauvegarde s√©curis√©e
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, ensure_ascii=False, indent=2)

        return True
    except Exception as e:
        print(f"Erreur de sauvegarde: {str(e)}")
        return False

def get_all_stats():
    """R√©cup√©ration des statistiques"""
    if not os.path.exists(HISTORY_FILE):
        return []

    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            stats = json.load(f)
        return stats if isinstance(stats, list) else []
    except Exception:
        return []

def calculate_metrics():
    """Calcul des m√©triques globales"""
    stats = get_all_stats()

    if not stats:
        return {}

    # Extraction des scores valides
    valid_scores = [stat.get("score") for stat in stats if stat.get("score") is not None]

    if not valid_scores:
        return {
            "total_analyses": len(stats),
            "avg_score": None,
            "high_score_count": 0,
            "high_score_percent": 0
        }

    # Calcul des m√©triques
    avg_score = sum(valid_scores) / len(valid_scores)
    high_score = sum(1 for score in valid_scores if score >= 7)
    high_score_percent = (high_score / len(valid_scores)) * 100

    return {
        "total_analyses": len(stats),
        "avg_score": avg_score,
        "high_score_count": high_score,
        "high_score_percent": high_score_percent,
        "scores_distribution": {
            "0-3": sum(1 for s in valid_scores if 0 <= s <= 3),
            "4-6": sum(1 for s in valid_scores if 4 <= s <= 6),
            "7-10": sum(1 for s in valid_scores if 7 <= s <= 10),
        }
    }

def delete_stats(student_name=None):
    """Suppression des stats avec protection"""
    if not os.path.exists(HISTORY_FILE):
        return True

    if student_name is None:
        # Suppression compl√®te
        try:
            os.remove(HISTORY_FILE)
            return True
        except:
            return False
    else:
        # Suppression s√©lective
        try:
            all_stats = get_all_stats()
            filtered_stats = [stat for stat in all_stats if stat.get("nom") != student_name]

            with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(filtered_stats, f, ensure_ascii=False, indent=2)
            return True
        except:
            return False

def generate_individual_pdf(result):
    """G√©n√©ration de PDF pour un √©tudiant"""
    try:
        pdf = FPDF()
        pdf.add_page()

        # Style et en-t√™te
        pdf.set_font("Arial", "B", 16)
        pdf.cell(0, 10, "Analyse d'Orientation Professionnelle", 0, 1, "C")
        pdf.line(10, 20, 200, 20)  # Ligne de s√©paration
        pdf.ln(5)

        # Informations √©tudiant
        pdf.set_font("Arial", "B", 12)
        pdf.cell(0, 10, f"√âtudiant: {result.get('Nom', 'Non sp√©cifi√©')}", 0, 1)
        pdf.cell(0, 10, f"Fili√®re: {result.get('Fili√®re', 'Non sp√©cifi√©e')}", 0, 1)
        pdf.cell(0, 10, f"Carri√®re vis√©e: {result.get('Carri√®re', 'Non sp√©cifi√©e')}", 0, 1)

        # Score avec code couleur
        score = result.get('score')
        if score is not None:
            if score >= 7:
                performance = "Excellent choix"
                pdf.set_text_color(0, 128, 0)  # Vert
            elif score >= 4:
                performance = "Choix √† am√©liorer"
                pdf.set_text_color(255, 128, 0)  # Orange
            else:
                performance = "R√©orientation recommand√©e"
                pdf.set_text_color(255, 0, 0)  # Rouge

            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, f"Score de coh√©rence: {score}/10 - {performance}", 0, 1)
            pdf.set_text_color(0, 0, 0)  # Retour au noir

        pdf.ln(5)

        # M√©tiers recommand√©s
        pdf.set_font("Arial", "B", 12)
        pdf.cell(0, 10, "M√©tiers recommand√©s:", 0, 1)

        pdf.set_font("Arial", "", 10)
        for job in result.get('recommended_jobs', []):
            pdf.cell(0, 8, f"‚Ä¢ {job}", 0, 1)

        if not result.get('recommended_jobs'):
            pdf.cell(0, 8, "Aucune recommandation sp√©cifique", 0, 1)

        pdf.ln(5)

        # Analyse d√©taill√©e
        pdf.set_font("Arial", "B", 12)
        pdf.cell(0, 10, "Analyse d√©taill√©e:", 0, 1)

        # Formatage du texte d'analyse
        if result.get('analysis'):
            pdf.set_font("Arial", "", 10)

            # D√©coupage en paragraphes pour √©viter les d√©passements
            analysis_text = result.get('analysis', '')
            paragraphs = analysis_text.split('\n')

            for para in paragraphs:
                if para.strip():
                    # Mettre en gras les titres de section
                    if any(section in para for section in ["NIVEAU DE COH√âRENCE", "ERREURS CRITIQUES", "RECOMMANDATIONS", "M√âTIERS RECOMMAND√âS"]):
                        pdf.set_font("Arial", "B", 10)
                        pdf.multi_cell(0, 5, para)
                        pdf.set_font("Arial", "", 10)
                    else:
                        pdf.multi_cell(0, 5, para)

        # Pied de page
        pdf.ln(10)
        pdf.set_font("Arial", "I", 8)
        pdf.cell(0, 10, f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}", 0, 1, "R")

        # Retourne le PDF
        return pdf.output(dest="S").encode("latin-1")
    except Exception as e:
        print(f"Erreur lors de la g√©n√©ration du PDF: {str(e)}")
        # PDF de secours en cas d'erreur
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", "B", 16)
        pdf.cell(0, 10, "Erreur de g√©n√©ration du PDF", 0, 1, "C")
        pdf.set_font("Arial", "", 12)
        pdf.cell(0, 10, f"Une erreur est survenue: {str(e)}", 0, 1)
        return pdf.output(dest="S").encode("latin-1")

def generate_group_pdf(results):
    """G√©n√©ration d'un PDF pour un groupe d'√©tudiants"""
    try:
        pdf = FPDF()
        pdf.add_page()

        # Titre et en-t√™te
        pdf.set_font("Arial", "B", 16)
        pdf.cell(0, 10, "Rapport d'Analyses d'Orientation", 0, 1, "C")
        pdf.line(10, 20, 200, 20)  # Ligne de s√©paration
        pdf.set_font("Arial", "", 10)
        pdf.cell(0, 10, f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}", 0, 1)

        # Synth√®se
        valid_scores = [r.get("score") for r in results if r.get("score") is not None]
        if valid_scores:
            avg_score = sum(valid_scores) / len(valid_scores)
            high_perf = sum(1 for s in valid_scores if s >= 7)
            medium_perf = sum(1 for s in valid_scores if 4 <= s <= 6)
            low_perf = sum(1 for s in valid_scores if s < 4)

            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, "Synth√®se des r√©sultats:", 0, 1)
            pdf.ln(2)

            pdf.set_font("Arial", "", 11)
            pdf.cell(0, 7, f"‚Ä¢ Nombre d'√©tudiants analys√©s: {len(results)}", 0, 1)
            pdf.cell(0, 7, f"‚Ä¢ Score moyen de coh√©rence: {avg_score:.1f}/10", 0, 1)

            # Statistiques avec code couleur
            pdf.set_text_color(0, 128, 0)  # Vert
            pdf.cell(0, 7, f"‚Ä¢ Choix excellents: {high_perf} ({high_perf/len(valid_scores)*100:.1f}%)", 0, 1)

            pdf.set_text_color(255, 128, 0)  # Orange
            pdf.cell(0, 7, f"‚Ä¢ Choix √† am√©liorer: {medium_perf} ({medium_perf/len(valid_scores)*100:.1f}%)", 0, 1)

            pdf.set_text_color(255, 0, 0)  # Rouge
            pdf.cell(0, 7, f"‚Ä¢ R√©orientations recommand√©es: {low_perf} ({low_perf/len(valid_scores)*100:.1f}%)", 0, 1)

            pdf.set_text_color(0, 0, 0)  # Retour au noir

        # R√©capitulatif des m√©tiers recommand√©s
        if any('recommended_jobs' in r and r['recommended_jobs'] for r in results):
            pdf.ln(5)
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, "M√©tiers les plus recommand√©s:", 0, 1)

            # Comptage des m√©tiers recommand√©s
            job_counts = {}
            for r in results:
                for job in r.get('recommended_jobs', []):
                    job_counts[job] = job_counts.get(job, 0) + 1

            # Tri par fr√©quence
            top_jobs = sorted(job_counts.items(), key=lambda x: x[1], reverse=True)[:10]

            pdf.set_font("Arial", "", 11)
            for job, count in top_jobs:
                pdf.cell(0, 7, f"‚Ä¢ {job}: {count} fois", 0, 1)

        # Tableau r√©capitulatif par √©tudiant
        pdf.add_page()
        pdf.set_font("Arial", "B", 14)
        pdf.cell(0, 10, "Tableau r√©capitulatif par √©tudiant:", 0, 1)

        # En-t√™te de tableau
        pdf.set_font("Arial", "B", 10)
        pdf.cell(45, 7, "Nom", 1, 0, "C")
        pdf.cell(45, 7, "Fili√®re", 1, 0, "C")
        pdf.cell(45, 7, "Carri√®re vis√©e", 1, 0, "C")
        pdf.cell(25, 7, "Score", 1, 0, "C")
        pdf.cell(30, 7, "√âvaluation", 1, 1, "C")

        # Donn√©es du tableau
        pdf.set_font("Arial", "", 9)
        for result in sorted(results, key=lambda x: x.get('score', 0) if x.get('score') is not None else -1, reverse=True):
            nom = result.get("Nom", "")
            filiere = result.get("Fili√®re", "")
            carriere = result.get("Carri√®re", "")
            score = result.get("score", "N/A")

            # D√©finir la couleur en fonction du score
            if score != "N/A":
                if score >= 7:
                    pdf.set_text_color(0, 128, 0)  # Vert
                    evaluation = "Excellent"
                elif score >= 4:
                    pdf.set_text_color(255, 128, 0)  # Orange
                    evaluation = "√Ä am√©liorer"
                else:
                    pdf.set_text_color(255, 0, 0)  # Rouge
                    evaluation = "Critique"
            else:
                pdf.set_text_color(0, 0, 0)  # Noir
                evaluation = "N/A"

            # Limiter la longueur des textes
            nom_display = nom[:20] + "..." if len(nom) > 20 else nom
            filiere_display = filiere[:20] + "..." if len(filiere) > 20 else filiere
            carriere_display = carriere[:20] + "..." if len(carriere) > 20 else carriere

            pdf.cell(45, 7, nom_display, 1, 0)
            pdf.cell(45, 7, filiere_display, 1, 0)
            pdf.cell(45, 7, carriere_display, 1, 0)
            pdf.cell(25, 7, f"{score}/10" if score != "N/A" else "N/A", 1, 0, "C")
            pdf.cell(30, 7, evaluation, 1, 1, "C")

            pdf.set_text_color(0, 0, 0)  # Retour au noir

        # D√©tails individuels
        pdf.add_page()
        pdf.set_font("Arial", "B", 14)
        pdf.cell(0, 10, "Analyses individuelles:", 0, 1)

        # Maximum 10 analyses d√©taill√©es pour √©viter un PDF trop volumineux
        for i, result in enumerate(sorted(results, key=lambda x: x.get('score', 0) if x.get('score') is not None else -1, reverse=True)[:10]):
            pdf.ln(5)
            pdf.set_font("Arial", "B", 12)
            nom = result.get("Nom", "")
            score = result.get("score", "N/A")

            # Couleur selon score
            if score != "N/A":
                if score >= 7:
                    pdf.set_text_color(0, 128, 0)  # Vert
                elif score >= 4:
                    pdf.set_text_color(255, 128, 0)  # Orange
                else:
                    pdf.set_text_color(255, 0, 0)  # Rouge

            pdf.cell(0, 10, f"{nom} - Score: {score}/10", 0, 1)
            pdf.set_text_color(0, 0, 0)  # Retour au noir

            pdf.set_font("Arial", "", 9)

            # Fili√®re et carri√®re
            filiere = result.get("Fili√®re", "")
            carriere = result.get("Carri√®re", "")
            pdf.cell(0, 6, f"Fili√®re: {filiere}", 0, 1)
            pdf.cell(0, 6, f"Carri√®re vis√©e: {carriere}", 0, 1)

            # M√©tiers recommand√©s
            pdf.set_font("Arial", "B", 9)
            pdf.cell(0, 6, "M√©tiers recommand√©s:", 0, 1)
            pdf.set_font("Arial", "", 9)

            for job in result.get('recommended_jobs', []):
                pdf.cell(0, 5, f"‚Ä¢ {job}", 0, 1)

            if not result.get('recommended_jobs'):
                pdf.cell(0, 5, "Aucune recommandation sp√©cifique", 0, 1)

            # R√©sum√© de l'analyse
            pdf.set_font("Arial", "B", 9)
            pdf.cell(0, 6, "R√©sum√© de l'analyse:", 0, 1)
            pdf.set_font("Arial", "", 9)

            # Extrait de l'analyse - limit√© pour √©viter les d√©bordements
            analysis = result.get("analysis", "")
            summary = analysis[:400] + "..." if len(analysis) > 400 else analysis
            pdf.multi_cell(0, 4, summary)

            # Ligne de s√©paration sauf pour le dernier
            if i < min(len(results), 10) - 1:
                pdf.ln(2)
                pdf.line(10, pdf.get_y(), 200, pdf.get_y())

        # Note de fin
        if len(results) > 10:
            pdf.ln(5)
            pdf.set_font("Arial", "I", 9)
            pdf.cell(0, 6, f"Note: Seulement les 10 premiers r√©sultats sont affich√©s en d√©tail sur {len(results)} analyses.", 0, 1)

        return pdf.output(dest="S").encode("latin-1")
    except Exception as e:
        print(f"Erreur lors de la g√©n√©ration du PDF de groupe: {str(e)}")
        # PDF de secours en cas d'erreur
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", "B", 16)
        pdf.cell(0, 10, "Erreur de g√©n√©ration du rapport PDF", 0, 1, "C")
        pdf.set_font("Arial", "", 12)
        pdf.cell(0, 10, f"Une erreur est survenue: {str(e)}", 0, 1)
        return pdf.output(dest="S").encode("latin-1")

def create_wordcloud(text_data, title="Nuage de mots"):
    """G√©n√®re un nuage de mots √† partir de donn√©es textuelles"""
    try:
        # Cr√©ation du nuage de mots
        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            colormap='viridis',
            max_words=100,
            contour_width=1,
            contour_color='steelblue'
        ).generate(text_data)

        # Configuration matplotlib
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        plt.title(title)

        # Conversion en image
        img_bytes = io.BytesIO()
        plt.savefig(img_bytes, format='png', bbox_inches='tight')
        img_bytes.seek(0)
        plt.close()

        return img_bytes
    except Exception as e:
        print(f"Erreur lors de la cr√©ation du nuage de mots: {str(e)}")
        return None

# --- INTERFACE DE NAVIGATION ---
st.sidebar.title("‚ö° Analyseur Pro")
menu = st.sidebar.radio(
    "Navigation",
    ["Accueil", "Analyse d'orientation", "Performances", "Analyses avanc√©es", "Configuration API", "√Ä propos"],
    label_visibility="collapsed"
)

# Affichage du statut API dans la sidebar
api_status_placeholder = st.sidebar.empty()
if API_KEY:
    api_status_placeholder.success("‚úÖ API configur√©e")
else:
    api_status_placeholder.error("‚õî API non configur√©e")

# --- PAGES DE L'APPLICATION ---

# --- 1. PAGE D'ACCUEIL ---
if menu == "Accueil":
    st.title("‚ö° ANALYSEUR D'ORIENTATION PROFESSIONNELLE")
    st.markdown("### D√©tection impitoyable des incoh√©rences de carri√®re")

    # Pr√©sentation
    st.markdown("""
    Bienvenue dans l'outil de d√©tection d'orientation le plus brutalement honn√™te du march√©.
    
    Notre analyse IA ne m√©nage pas vos √©tudiants. Elle identifie les erreurs d'orientation
    avec une pr√©cision chirurgicale et fournit des recommandations concr√®tes.
    """)

    # Fonctionnalit√©s
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### üîç Fonctionnalit√©s")
        st.markdown("""
        - **Analyse impitoyable** des choix d'orientation
        - **D√©tection automatique** des compatibilit√©s fili√®re/carri√®re  
        - **Scoring pr√©cis** sur une √©chelle de 0 √† 10
        - **Suggestions de m√©tiers** pertinentes
        - **Recommandations concr√®tes** pour r√©orientation
        - **Export imm√©diat** des r√©sultats (CSV, JSON, PDF)
        - **Analyses avanc√©es** des tendances
        """)

    with col2:
        metrics = calculate_metrics()
        if metrics:
            st.markdown("### üìä Statistiques globales")

            total = metrics.get("total_analyses", 0)
            avg = metrics.get("avg_score")
            high_score = metrics.get("high_score_percent", 0)

            st.metric("Analyses r√©alis√©es", total)
            if avg is not None:
                st.metric("Score moyen de coh√©rence", f"{avg:.1f}/10")
            st.metric("Orientations optimales", f"{high_score:.1f}%")
        else:
            st.info("Aucune analyse encore r√©alis√©e. Commencez d√®s maintenant!")

    # D√©marrage rapide
    st.markdown("### ‚ö° D√©marrage rapide")

    if not API_KEY:
        st.warning("‚ö†Ô∏è Configuration API requise")
        if st.button("Configurer l'API maintenant"):
            menu = "Configuration API"
            st.rerun()
    else:
        if st.button("Commencer une analyse"):
            menu = "Analyse d'orientation"
            st.rerun()


# --- 2. PAGE D'ANALYSE ---
elif menu == "Analyse d'orientation":
    st.title("üîç Analyse d'orientation")

    # Upload file section
    st.subheader("1. Importer vos donn√©es")

    # File uploader
    uploaded_file = st.file_uploader("Fichier CSV/Excel", type=["csv", "xlsx", "xls"])

    if uploaded_file:
        # Process file
        df, error = load_file(uploaded_file)

        if error:
            st.error(f"Erreur: {error}")
        elif df is not None:
            st.success(f"Fichier charg√©: {len(df)} √©tudiants")

            # Find columns (simplified)
            name_col = next((col for col in df.columns if 'nom' in str(col).lower()), df.columns[0])
            filiere_col = next((col for col in df.columns if 'fili' in str(col).lower()), df.columns[1])
            career_col = next((col for col in df.columns if 'carr' in str(col).lower() or 'envis' in str(col).lower()), df.columns[2])

            # Show detected columns
            st.write(f"Colonnes d√©tect√©es: Nom='{name_col}', Fili√®re='{filiere_col}', Carri√®re='{career_col}'")

            # Clean data
            df["filiere_clean"] = df[filiere_col].astype(str).apply(sanitize_text)
            df["carriere_clean"] = df[career_col].astype(str).apply(sanitize_text)

            # Selection options
            st.subheader("2. Configurer l'analyse")

            analysis_type = st.radio(
                "S√©lection:",
                ["Tous les √©tudiants", "S√©lection manuelle", "√âchantillon al√©atoire"]
            )

            students_to_analyze = df

            if analysis_type == "S√©lection manuelle":
                selected = st.multiselect(
                    "S√©lectionner les √©tudiants:",
                    df[name_col].unique()
                )
                if selected:
                    students_to_analyze = df[df[name_col].isin(selected)]
                else:
                    st.warning("S√©lectionnez au moins un √©tudiant")

            elif analysis_type == "√âchantillon al√©atoire":
                sample_size = st.slider(
                    "Nombre d'√©tudiants:",
                    1, min(len(df), 20), 5
                )
                students_to_analyze = df.sample(sample_size)

            # Analysis button
            if not API_KEY:
                st.error("‚õî API non configur√©e. Allez dans Configuration API")
            else:
                if st.button("‚ö° LANCER L'ANALYSE", type="primary"):
                    # Progress tracking
                    progress = st.progress(0)
                    status_text = st.empty()
                    results = []

                    # Start time
                    start_time = time.time()

                    # Analyze each student
                    for i, (_, student) in enumerate(students_to_analyze.iterrows()):
                        status_text.write(f"Analyse de {student[name_col]}...")

                        # Run analysis
                        analysis_result = analyze_career({
                            "filiere": student["filiere_clean"],
                            "carriere": student["carriere_clean"]
                        })

                        # Store result
                        results.append({
                            "Nom": student[name_col],
                            "Fili√®re": student[filiere_col],
                            "Carri√®re": student[career_col],
                            "analysis": analysis_result.get("analysis", f"ERREUR: {analysis_result.get('error')}"),
                            "score": analysis_result.get("score"),
                            "recommended_jobs": analysis_result.get("recommended_jobs", [])
                        })

                        # Update progress
                        progress.progress((i + 1) / len(students_to_analyze))

                    # End time and clear status
                    total_time = time.time() - start_time
                    status_text.empty()

                    # Save results to history
                    save_to_history(results)

                    # Display results
                    st.subheader("R√©sultats d'analyse")
                    st.success(f"Analyse compl√©t√©e en {total_time:.1f} secondes")

                    # Show metrics if scores available
                    valid_scores = [r.get("score") for r in results if r.get("score") is not None]
                    if valid_scores:
                        avg_score = sum(valid_scores) / len(valid_scores)
                        high_score = sum(1 for s in valid_scores if s >= 7)

                        # Display metrics
                        col1, col2, col3 = st.columns(3)
                        col1.metric("Score moyen", f"{avg_score:.1f}/10")
                        col2.metric("Excellentes orientations", f"{high_score}/{len(valid_scores)}")
                        col3.metric("Pourcentage optimal", f"{high_score/len(valid_scores)*100:.1f}%")

                        # Sort by score (highest first)
                        results.sort(key=lambda x: (x.get("score") is None, -1 * (x.get("score") or 0)))

                    # Display individual results
                    for result in results:
                        name = result.get("Nom", "")
                        filiere = result.get("Fili√®re", "")
                        carriere = result.get("Carri√®re", "")
                        score = result.get("score")
                        analysis = result.get("analysis", "")
                        recommended_jobs = result.get("recommended_jobs", [])

                        # Format display based on score
                        if score is not None:
                            if score >= 7:
                                emoji = "‚úÖ"
                                color = "green"
                                performance = "Excellent choix"
                            elif score >= 4:
                                emoji = "‚ö†Ô∏è"
                                color = "orange"
                                performance = "√Ä am√©liorer"
                            else:
                                emoji = "üö®"
                                color = "red"
                                performance = "R√©orientation conseill√©e"

                            title = f"{emoji} {name} - {filiere} ‚Üí {carriere} (Score: {score}/10 - {performance})"
                        else:
                            title = f"üìä {name} - {filiere} ‚Üí {carriere}"
                            color = "gray"

                        # Display analysis in expandable section
                        with st.expander(title):
                            # Affiche les m√©tiers recommand√©s
                            if recommended_jobs:
                                st.markdown("#### M√©tiers recommand√©s:")
                                for job in recommended_jobs:
                                    st.markdown(f"* **{job}**")
                                st.markdown("---")

                            # Affiche l'analyse compl√®te
                            st.markdown(f"<div style='color:{color};'>{analysis}</div>",
                                        unsafe_allow_html=True)

                    # Export options
                    st.subheader("Exporter les r√©sultats")

                    col1, col2 = st.columns(2)

                    with col1:
                        if st.button("üì• EXPORTER EN CSV", type="primary"):
                            try:
                                # V√©rification des donn√©es
                                if not results or len(results) == 0:
                                    st.error("ERREUR: Aucun r√©sultat √† exporter.")
                                    st.stop()

                                # Cr√©ation du DataFrame avec les m√©tiers recommand√©s
                                export_df = pd.DataFrame(results)

                                # Conversion de la liste de m√©tiers en cha√Æne pour CSV
                                export_df['recommended_jobs'] = export_df['recommended_jobs'].apply(
                                    lambda x: ', '.join(x) if isinstance(x, list) else '')

                                # M√âTHODE DIRECTE
                                csv_data = export_df.to_csv(index=False).encode('utf-8')

                                # T√©l√©chargement imm√©diat
                                st.download_button(
                                    "‚¨áÔ∏è T√âL√âCHARGER LE CSV",
                                    data=csv_data,
                                    file_name=f"analyse_orientation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv",
                                )

                                st.success("‚úÖ CSV g√©n√©r√© avec succ√®s.")

                            except Exception as e:
                                st.error(f"ERREUR: {str(e)}")

                    with col2:
                        if st.button("üìä EXPORTER EN JSON"):
                            try:
                                if not results or len(results) == 0:
                                    st.error("ERREUR: Aucun r√©sultat √† exporter.")
                                    st.stop()

                                # Export JSON
                                json_str = json.dumps(results, ensure_ascii=False, indent=2)

                                # T√©l√©chargement
                                st.download_button(
                                    "‚¨áÔ∏è T√âL√âCHARGER LE JSON",
                                    data=json_str.encode('utf-8'),
                                    file_name=f"analyse_orientation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                    mime="application/json",
                                )

                                st.success("‚úÖ JSON g√©n√©r√© avec succ√®s.")

                            except Exception as e:
                                st.error(f"ERREUR: {str(e)}")

                    # Export PDF
                    st.subheader("Exporter en PDF")

                    col1, col2 = st.columns(2)

                    with col1:
                        if st.button("üìÑ PDF INDIVIDUELS"):
                            # Afficher un bouton de t√©l√©chargement pour chaque √©tudiant
                            for result in results:
                                try:
                                    nom = result.get("Nom", "etudiant")
                                    pdf_data = generate_individual_pdf(result)

                                    st.download_button(
                                        f"‚¨áÔ∏è PDF pour {nom}",
                                        data=pdf_data,
                                        file_name=f"analyse_{nom.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.pdf",
                                        mime="application/pdf",
                                        key=f"pdf_{nom}".replace(" ", "_"),
                                    )
                                except Exception as e:
                                    st.error(f"Erreur pour {result.get('Nom', '√©tudiant')}: {str(e)}")

                    with col2:
                        if st.button("üìë RAPPORT GROUP√â"):
                            try:
                                pdf_data = generate_group_pdf(results)

                                st.download_button(
                                    "‚¨áÔ∏è T√âL√âCHARGER LE RAPPORT PDF",
                                    data=pdf_data,
                                    file_name=f"rapport_orientation_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                                    mime="application/pdf",
                                )

                                st.success("‚úÖ Rapport PDF g√©n√©r√© avec succ√®s.")
                            except Exception as e:
                                st.error(f"ERREUR: {str(e)}")


# --- 3. PAGE DE PERFORMANCES ---
elif menu == "Performances":
    st.title("üìä Performances d'orientation")

    # R√©cup√©ration des statistiques
    all_stats = get_all_stats()

    if not all_stats:
        st.info("Aucune statistique disponible. Effectuez des analyses pour g√©n√©rer des donn√©es.")
    else:
        # M√©triques globales
        metrics = calculate_metrics()

        st.subheader("Vue d'ensemble")

        # Affichage des m√©triques cl√©s
        col1, col2, col3 = st.columns(3)
        col1.metric("Analyses r√©alis√©es", metrics.get("total_analyses", 0))

        if metrics.get("avg_score") is not None:
            col2.metric("Score moyen de coh√©rence", f"{metrics.get('avg_score', 0):.1f}/10")
        else:
            col2.metric("Score moyen de coh√©rence", "N/A")

        col3.metric("Excellentes orientations", f"{metrics.get('high_score_percent', 0):.1f}%")

        # Pr√©paration pour visualisations
        try:
            # Conversion en DataFrame
            stats_df = pd.DataFrame(all_stats)

            # L√©gendage des niveaux de risque
            if 'score' in stats_df.columns:
                # Distribution des scores en barres
                scores = stats_df['score'].dropna()
                if not scores.empty:
                    score_dist = pd.cut(
                        scores,
                        bins=[0, 3, 6, 10],
                        labels=['0-3: R√©orientation', '4-6: √Ä surveiller', '7-10: Excellent']
                    ).value_counts().sort_index()

                    fig = px.bar(
                        x=score_dist.index,
                        y=score_dist.values,
                        title="Distribution des niveaux de coh√©rence",
                        labels={'x': 'Niveau', 'y': 'Nombre d\'√©tudiants'},
                        color=score_dist.index,
                        color_discrete_map={
                            '0-3: R√©orientation': '#FF4B4B',
                            '4-6: √Ä surveiller': '#FFA726',
                            '7-10: Excellent': '#4CAF50'
                        }
                    )
                    st.plotly_chart(fig, use_container_width=True)

                # Conversion des timestamps
                stats_df['date'] = pd.to_datetime(stats_df['timestamp']).dt.date

                # Graphique d'√©volution temporelle
                if len(stats_df) >= 3:
                    st.subheader("√âvolution des scores dans le temps")

                    # Calcul des moyennes quotidiennes
                    daily_avg = stats_df.groupby('date')['score'].mean().reset_index()
                    daily_avg.columns = ['Date', 'Score moyen']

                    # Graphique
                    if not daily_avg.empty:
                        fig = px.line(
                            daily_avg,
                            x='Date',
                            y='Score moyen',
                            title="√âvolution des scores de coh√©rence",
                            markers=True
                        )
                        fig.update_layout(yaxis_range=[0, 10])
                        st.plotly_chart(fig, use_container_width=True)

                # Analyse des m√©tiers recommand√©s
                if 'recommended_jobs' in stats_df.columns:
                    all_jobs = []
                    for jobs_list in stats_df['recommended_jobs']:
                        if isinstance(jobs_list, list):
                            all_jobs.extend(jobs_list)

                    if all_jobs:
                        # Comptage des m√©tiers
                        job_counts = pd.Series(all_jobs).value_counts().reset_index()
                        job_counts.columns = ['M√©tier', 'Fr√©quence']

                        # Affichage des m√©tiers les plus recommand√©s
                        st.subheader("M√©tiers les plus recommand√©s")

                        top_n = min(10, len(job_counts))
                        fig = px.bar(
                            job_counts.head(top_n),
                            x='M√©tier',
                            y='Fr√©quence',
                            title=f"Top {top_n} des m√©tiers les plus recommand√©s",
                            color='Fr√©quence',
                            color_continuous_scale='Viridis'
                        )
                        st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration des graphiques: {str(e)}")

        # Liste des √©tudiants analys√©s
        st.subheader("Historique par √©tudiant")

        # Extraction des √©tudiants uniques
        students = list(set(stat.get('nom') for stat in all_stats if stat.get('nom')))
        students.sort()  # Tri alphab√©tique

        if not students:
            st.warning("Aucun √©tudiant identifi√© dans les donn√©es.")
        else:
            for student in students:
                # Filtrer les donn√©es pour cet √©tudiant
                student_stats = [stat for stat in all_stats if stat.get('nom') == student]

                if student_stats:
                    # Calculer le score moyen
                    valid_scores = [stat.get('score') for stat in student_stats if stat.get('score') is not None]

                    avg_score = sum(valid_scores) / len(valid_scores) if valid_scores else None
                    score_display = f" - Score moyen: {avg_score:.1f}/10" if avg_score is not None else ""

                    # D√©finir la couleur en fonction du score
                    if avg_score is not None:
                        if avg_score >= 7:
                            color = "green"
                            emoji = "‚úÖ"
                        elif avg_score >= 4:
                            color = "orange"
                            emoji = "‚ö†Ô∏è"
                        else:
                            color = "red"
                            emoji = "üö®"
                    else:
                        color = "gray"
                        emoji = "üìä"

                    # Affichage par √©tudiant
                    with st.expander(f"{emoji} {student}{score_display}"):
                        # Trier par date (plus r√©cent en premier)
                        sorted_stats = sorted(
                            student_stats,
                            key=lambda x: x.get('timestamp', ''),
                            reverse=True
                        )

                        # Colonnes pour les m√©tiers recommand√©s
                        col1, col2 = st.columns([3, 1])

                        with col1:
                            # Tableau des analyses
                            for stat in sorted_stats:
                                timestamp = datetime.fromisoformat(stat.get('timestamp', '')).strftime('%d/%m/%Y %H:%M') \
                                    if stat.get('timestamp') else "Date inconnue"

                                st.markdown(f"""
                                **üìÖ {timestamp}**
                                - **Fili√®re:** {stat.get('filiere', 'Non sp√©cifi√©e')}
                                - **Carri√®re vis√©e:** {stat.get('carriere', 'Non sp√©cifi√©e')}
                                - **Score de coh√©rence:** {stat.get('score', 'N/A')}/10
                                
                                <div style='color:{color};'>{stat.get('analysis', 'Aucune analyse disponible')}</div>
                                ---
                                """, unsafe_allow_html=True)

                        with col2:
                            # Liste des m√©tiers recommand√©s pour cet √©tudiant
                            all_student_jobs = []
                            for stat in sorted_stats:
                                if 'recommended_jobs' in stat and stat['recommended_jobs']:
                                    all_student_jobs.extend(stat['recommended_jobs'])

                            if all_student_jobs:
                                st.markdown("#### M√©tiers recommand√©s:")
                                job_counts = pd.Series(all_student_jobs).value_counts()
                                for job, count in job_counts.items():
                                    st.markdown(f"- **{job}** ({count})")

                                # Option PDF individuel
                                if st.button(f"üìÑ PDF pour {student}", key=f"btn_pdf_{student}".replace(" ", "_")):
                                    # Cr√©er un PDF pour le dernier rapport (le plus r√©cent)
                                    latest_stat = sorted_stats[0]
                                    result = {
                                        "Nom": student,
                                        "Fili√®re": latest_stat.get('filiere', ''),
                                        "Carri√®re": latest_stat.get('carriere', ''),
                                        "score": latest_stat.get('score'),
                                        "analysis": latest_stat.get('analysis', ''),
                                        "recommended_jobs": latest_stat.get('recommended_jobs', [])
                                    }

                                    try:
                                        pdf_data = generate_individual_pdf(result)

                                        st.download_button(
                                            f"‚¨áÔ∏è T√©l√©charger PDF",
                                            data=pdf_data,
                                            file_name=f"analyse_{student.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.pdf",
                                            mime="application/pdf",
                                            key=f"dl_pdf_{student}".replace(" ", "_")
                                        )
                                    except Exception as e:
                                        st.error(f"Erreur: {str(e)}")

        # Bouton pour exporter les statistiques
        st.subheader("Exportation des donn√©es")
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("üì• EXPORTER L'HISTORIQUE COMPLET"):
                try:
                    # Export JSON
                    json_str = json.dumps(all_stats, ensure_ascii=False, indent=2)

                    # T√©l√©chargement
                    st.download_button(
                        "‚¨áÔ∏è T√âL√âCHARGER L'HISTORIQUE",
                        data=json_str.encode('utf-8'),
                        file_name=f"historique_analyses_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                    )

                    st.success("‚úÖ Historique export√© avec succ√®s.")

                except Exception as e:
                    st.error(f"ERREUR: {str(e)}")

        with col2:
            if st.button("üìä RAPPORT GLOBAL PDF"):
                try:
                    # Cr√©ation d'un rapport global √† partir de tous les stats
                    results = []
                    for stat in all_stats:
                        results.append({
                            "Nom": stat.get('nom', 'Anonyme'),
                            "Fili√®re": stat.get('filiere', ''),
                            "Carri√®re": stat.get('carriere', ''),
                            "score": stat.get('score'),
                            "analysis": stat.get('analysis', ''),
                            "recommended_jobs": stat.get('recommended_jobs', [])
                        })

                    pdf_data = generate_group_pdf(results)

                    st.download_button(
                        "‚¨áÔ∏è T√âL√âCHARGER LE RAPPORT PDF",
                        data=pdf_data,
                        file_name=f"rapport_global_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                        mime="application/pdf",
                    )

                    st.success("‚úÖ Rapport PDF g√©n√©r√© avec succ√®s.")
                except Exception as e:
                    st.error(f"ERREUR: {str(e)}")

        # Bouton pour supprimer tout l'historique
        with col3:
            if st.button("üóëÔ∏è SUPPRIMER TOUT L'HISTORIQUE", type="secondary"):
                confirm = st.checkbox("Confirmer la suppression permanente")

                if confirm:
                    success = delete_stats()
                    if success:
                        st.success("Tout l'historique a √©t√© supprim√©")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("Erreur lors de la suppression de l'historique")


# --- 4. PAGE D'ANALYSES AVANC√âES ---
elif menu == "Analyses avanc√©es":
    st.title("üî¨ Analyses avanc√©es")

    # R√©cup√©ration des statistiques
    all_stats = get_all_stats()

    if not all_stats:
        st.info("Aucune donn√©e disponible. Effectuez des analyses pour g√©n√©rer des donn√©es.")
    else:
        # Conversion en DataFrame pour analyses
        try:
            stats_df = pd.DataFrame(all_stats)

            # Navigation
            analyse_type = st.radio(
                "Type d'analyse:",
                ["Compatibilit√© fili√®re-carri√®re", "Nuages de mots", "Tendances temporelles", "Exportation avanc√©e"]
            )

            # 1. MATRICE DE COMPATIBILIT√â
            if analyse_type == "Compatibilit√© fili√®re-carri√®re":
                st.subheader("Matrice de compatibilit√© fili√®re-carri√®re")
                st.markdown("""
                Cette visualisation montre les scores moyens de coh√©rence entre 
                les diff√©rentes fili√®res et carri√®res analys√©es.
                """)

                # V√©rification du nombre de donn√©es
                if len(stats_df) < 3:
                    st.warning("Donn√©es insuffisantes pour g√©n√©rer une matrice de compatibilit√©.")
                else:
                    # Extraction des fili√®res et carri√®res uniques
                    filieres = stats_df['filiere'].dropna().unique()
                    carrieres = stats_df['carriere'].dropna().unique()

                    if len(filieres) > 1 and len(carrieres) > 1:
                        # Cr√©ation d'une matrice de scores moyens
                        compatibility_data = []
                        heatmap_x = []
                        heatmap_y = []

                        for filiere in filieres:
                            for carriere in carrieres:
                                subset = stats_df[(stats_df['filiere'] == filiere) &
                                                  (stats_df['carriere'] == carriere)]
                                if not subset.empty and 'score' in subset.columns:
                                    avg_score = subset['score'].mean()
                                    if not pd.isna(avg_score):
                                        compatibility_data.append(avg_score)
                                        heatmap_x.append(carriere)
                                        heatmap_y.append(filiere)

                        if compatibility_data:
                            # Cr√©ation du graphique heatmap
                            fig = go.Figure(data=go.Heatmap(
                                z=compatibility_data,
                                x=heatmap_x,
                                y=heatmap_y,
                                colorscale='RdYlGn',  # Rouge √† Vert
                                colorbar=dict(title='Score'),
                                hoverongaps=False
                            ))

                            fig.update_layout(
                                title="Matrice de compatibilit√© Fili√®re/Carri√®re",
                                xaxis_title="Carri√®re vis√©e",
                                yaxis_title="Fili√®re actuelle",
                                height=600,
                                xaxis={'categoryorder':'category ascending'},
                                yaxis={'categoryorder':'category ascending'}
                            )

                            st.plotly_chart(fig, use_container_width=True)

                            st.info("""
                            **Comment lire cette matrice:**
                            - Les cases vertes indiquent une forte compatibilit√© (score √©lev√©)
                            - Les cases rouges indiquent une faible compatibilit√© (score bas)
                            - Les zones vides indiquent qu'aucune analyse n'a √©t√© faite pour cette combinaison
                            """)
                    else:
                        st.warning("Diversit√© insuffisante dans les donn√©es pour cr√©er une matrice.")

                # Analyse des carri√®res bien not√©es par fili√®re
                if 'filiere' in stats_df.columns and 'carriere' in stats_df.columns and 'score' in stats_df.columns:
                    st.subheader("Meilleures carri√®res par fili√®re")

                    # Regroupement par fili√®re et carri√®re
                    grouped = stats_df.groupby(['filiere', 'carriere'])['score'].mean().reset_index()

                    # Top carri√®res pour chaque fili√®re
                    top_careers = []
                    for filiere in grouped['filiere'].unique():
                        filiere_data = grouped[grouped['filiere'] == filiere]
                        top_careers_for_filiere = filiere_data.nlargest(3, 'score')
                        top_careers.append({
                            'Fili√®re': filiere,
                            'Top carri√®res': top_careers_for_filiere
                        })

                    # Affichage des r√©sultats
                    for entry in top_careers:
                        filiere = entry['Fili√®re']
                        top = entry['Top carri√®res']

                        if not top.empty:
                            st.markdown(f"**{filiere}**")
                            for _, row in top.iterrows():
                                score_color = "green" if row['score'] >= 7 else "orange" if row['score'] >= 4 else "red"
                                st.markdown(f"- {row['carriere']} - <span style='color:{score_color};'>Score: {row['score']:.1f}/10</span>", unsafe_allow_html=True)

            # 2. NUAGES DE MOTS
            elif analyse_type == "Nuages de mots":
                st.subheader("Analyse textuelle")

                # Options d'analyse
                text_analysis_type = st.selectbox(
                    "S√©lectionnez le type d'analyse textuelle:",
                    ["Nuage des fili√®res", "Nuage des carri√®res", "Nuage des m√©tiers recommand√©s", "Nuage des erreurs critiques"]
                )

                # Pr√©paration des donn√©es selon le type d'analyse
                if text_analysis_type == "Nuage des fili√®res":
                    text_data = " ".join(stats_df['filiere'].dropna().astype(str))
                    title = "Fili√®res les plus courantes"

                elif text_analysis_type == "Nuage des carri√®res":
                    text_data = " ".join(stats_df['carriere'].dropna().astype(str))
                    title = "Carri√®res les plus vis√©es"

                elif text_analysis_type == "Nuage des m√©tiers recommand√©s":
                    # Extrait tous les m√©tiers recommand√©s
                    all_jobs = []
                    for jobs in stats_df['recommended_jobs']:
                        if isinstance(jobs, list):
                            all_jobs.extend(jobs)
                    text_data = " ".join(all_jobs)
                    title = "M√©tiers les plus recommand√©s"

                elif text_analysis_type == "Nuage des erreurs critiques":
                    # Extraction des erreurs critiques des analyses
                    errors_section = []
                    pattern = r"ERREURS CRITIQUES:(.*?)(?:RECOMMANDATIONS:|$)"

                    for analysis in stats_df['analysis'].dropna():
                        matches = re.search(pattern, analysis, re.DOTALL)
                        if matches:
                            errors_section.append(matches.group(1))

                    text_data = " ".join(errors_section)
                    title = "Comp√©tences manquantes les plus fr√©quentes"

                # G√©n√©ration du nuage de mots
                if text_data and len(text_data) > 10:
                    img_bytes = create_wordcloud(text_data, title)

                    if img_bytes:
                        st.image(img_bytes, use_column_width=True)

                        # Option d'export de l'image
                        img_str = base64.b64encode(img_bytes.getvalue()).decode()
                        href = f'<a href="data:file/png;base64,{img_str}" download="wordcloud_{text_analysis_type.lower().replace(" ", "_")}.png">T√©l√©charger l\'image</a>'
                        st.markdown(href, unsafe_allow_html=True)
                    else:
                        st.error("Impossible de g√©n√©rer le nuage de mots.")
                else:
                    st.warning("Donn√©es textuelles insuffisantes pour cette analyse.")

                # Analyse fr√©quentielle en plus du nuage
                if text_data and len(text_data) > 10:
                    st.subheader("Analyse fr√©quentielle")

                    # Nettoyage et tokenisation basique
                    words = re.findall(r'\b\w+\b', text_data.lower())
                    words = [w for w in words if len(w) > 2 and w not in ['les', 'des', 'pour', 'une', 'avec', 'dans']]

                    word_counts = pd.Series(words).value_counts().head(15)

                    # Graphique des fr√©quences
                    fig = px.bar(
                        x=word_counts.index,
                        y=word_counts.values,
                        title="Fr√©quence des termes",
                        labels={'x': 'Terme', 'y': 'Fr√©quence'},
                        color=word_counts.values,
                        color_continuous_scale='Viridis'
                    )
                    st.plotly_chart(fig, use_container_width=True)

            # 3. TENDANCES TEMPORELLES
            elif analyse_type == "Tendances temporelles":
                st.subheader("Analyse des tendances temporelles")

                # Conversion des timestamps
                if 'timestamp' in stats_df.columns:
                    stats_df['date'] = pd.to_datetime(stats_df['timestamp']).dt.date

                    if stats_df['date'].nunique() >= 3:
                        # Options de visualisation
                        time_metric = st.selectbox(
                            "S√©lectionnez la m√©trique √† analyser dans le temps:",
                            ["Score moyen", "Nombre d'analyses", "R√©partition des scores"]
                        )

                        if time_metric == "Score moyen":
                            # Calcul des moyennes quotidiennes
                            daily_avg = stats_df.groupby('date')['score'].mean().reset_index()
                            daily_avg.columns = ['Date', 'Score moyen']

                            # Courbe d'√©volution
                            fig = px.line(
                                daily_avg,
                                x='Date',
                                y='Score moyen',
                                title="√âvolution du score moyen de coh√©rence dans le temps",
                                markers=True
                            )
                            fig.update_layout(yaxis_range=[0, 10])
                            st.plotly_chart(fig, use_container_width=True)

                        elif time_metric == "Nombre d'analyses":
                            # Comptage par jour
                            daily_count = stats_df.groupby('date').size().reset_index()
                            daily_count.columns = ['Date', 'Nombre d\'analyses']

                            # Graphique
                            fig = px.bar(
                                daily_count,
                                x='Date',
                                y='Nombre d\'analyses',
                                title="Nombre d'analyses effectu√©es par jour",
                                color='Nombre d\'analyses',
                                color_continuous_scale='Viridis'
                            )
                            st.plotly_chart(fig, use_container_width=True)

                        elif time_metric == "R√©partition des scores":
                            # Cat√©gorisation des scores
                            stats_df['cat√©gorie'] = pd.cut(
                                stats_df['score'],
                                bins=[0, 3, 6, 10],
                                labels=['Faible (0-3)', 'Moyen (4-6)', '√âlev√© (7-10)']
                            )

                            # Comptage par cat√©gorie et par jour
                            daily_categories = pd.crosstab(
                                stats_df['date'],
                                stats_df['cat√©gorie']
                            ).reset_index()

                            # Mise en forme pour graphique
                            daily_categories_melted = pd.melt(
                                daily_categories,
                                id_vars=['date'],
                                var_name='Cat√©gorie',
                                value_name='Nombre'
                            )

                            # Graphique empil√©
                            fig = px.area(
                                daily_categories_melted,
                                x='date',
                                y='Nombre',
                                color='Cat√©gorie',
                                title="√âvolution de la r√©partition des scores dans le temps",
                                color_discrete_map={
                                    'Faible (0-3)': '#FF4B4B',
                                    'Moyen (4-6)': '#FFA726',
                                    '√âlev√© (7-10)': '#4CAF50'
                                }
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("Donn√©es temporelles insuffisantes pour l'analyse des tendances.")
                else:
                    st.error("Les donn√©es ne contiennent pas d'information temporelle.")

            # 4. EXPORTATION AVANC√âE
            elif analyse_type == "Exportation avanc√©e":
                st.subheader("Exportation et traitement avanc√© des donn√©es")

                # Options d'exportation
                export_option = st.radio(
                    "S√©lectionnez le format d'exportation:",
                    ["Tableau crois√© dynamique", "Matrice de corr√©lation", "Rapport analytique complet"]
                )

                if export_option == "Tableau crois√© dynamique":
                    st.markdown("""
                    Le tableau crois√© dynamique permet de visualiser la relation 
                    entre deux variables et une m√©trique.
                    """)

                    # Options du tableau
                    col1, col2 = st.columns(2)
                    with col1:
                        row_var = st.selectbox(
                            "Variable en ligne:",
                            ["filiere", "carriere"]
                        )
                    with col2:
                        col_var = st.selectbox(
                            "Variable en colonne:",
                            ["carriere", "filiere"],
                            index=1 if row_var == "filiere" else 0
                        )

                    # Cr√©ation du tableau crois√©
                    if row_var and col_var and row_var != col_var:
                        pivot = pd.pivot_table(
                            stats_df,
                            values='score',
                            index=row_var,
                            columns=col_var,
                            aggfunc='mean',
                            fill_value=None
                        )

                        # Affichage du tableau
                        st.markdown("### Tableau crois√© des scores moyens")
                        st.dataframe(pivot.style.background_gradient(cmap='RdYlGn', vmin=0, vmax=10))

                        # Export Excel
                        buffer = io.BytesIO()
                        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                            pivot.to_excel(writer, sheet_name='Pivot')

                            # Ajout de mise en forme conditionnelle
                            workbook = writer.book
                            worksheet = writer.sheets['Pivot']

                            # Format pour les scores
                            format_high = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
                            format_mid = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C5700'})
                            format_low = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})

                            # Mise en forme conditionnelle
                            worksheet.conditional_format(1, 1, len(pivot.index)+1, len(pivot.columns)+1, {
                                'type': '3_color_scale',
                                'min_color': '#FFC7CE',
                                'mid_color': '#FFEB9C',
                                'max_color': '#C6EFCE',
                                'min_value': 0,
                                'mid_value': 5,
                                'max_value': 10
                            })

                        excel_data = buffer.getvalue()

                        st.download_button(
                            "üìä T√©l√©charger le tableau Excel",
                            data=excel_data,
                            file_name=f"pivot_{row_var}_{col_var}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                            mime="application/vnd.ms-excel"
                        )

                elif export_option == "Matrice de corr√©lation":
                    st.markdown("""
                    Exploration des relations entre diff√©rentes variables et le score obtenu.
                    """)

                    # Pr√©paration des donn√©es
                    # Extraction de caract√©ristiques √† partir des textes
                    try:
                        # Longueur de la fili√®re et de la carri√®re
                        if 'filiere' in stats_df.columns and 'carriere' in stats_df.columns:
                            stats_df['longueur_filiere'] = stats_df['filiere'].astype(str).apply(len)
                            stats_df['longueur_carriere'] = stats_df['carriere'].astype(str).apply(len)

                            # Nombre de m√©tiers recommand√©s
                            if 'recommended_jobs' in stats_df.columns:
                                stats_df['nb_metiers_recommandes'] = stats_df['recommended_jobs'].apply(
                                    lambda x: len(x) if isinstance(x, list) else 0
                                )

                            # Cr√©ation de la matrice de corr√©lation
                            corr_cols = ['score', 'longueur_filiere', 'longueur_carriere']
                            if 'nb_metiers_recommandes' in stats_df.columns:
                                corr_cols.append('nb_metiers_recommandes')

                            corr_matrix = stats_df[corr_cols].corr()

                            # Affichage de la matrice
                            fig = px.imshow(
                                corr_matrix,
                                text_auto=True,
                                color_continuous_scale='RdBu_r',
                                title="Matrice de corr√©lation des variables"
                            )
                            st.plotly_chart(fig, use_container_width=True)

                            st.info("""
                            **Comment lire cette matrice:**
                            - Les valeurs proches de 1 indiquent une forte corr√©lation positive
                            - Les valeurs proches de -1 indiquent une forte corr√©lation n√©gative
                            - Les valeurs proches de 0 indiquent l'absence de corr√©lation
                            """)

                            # Export CSV
                            csv_corr = corr_matrix.to_csv(index=True).encode('utf-8')

                            st.download_button(
                                "üìä T√©l√©charger la matrice CSV",
                                data=csv_corr,
                                file_name=f"correlation_matrix_{datetime.now().strftime('%Y%m%d')}.csv",
                                mime="text/csv"
                            )
                    except Exception as e:
                        st.error(f"Erreur lors de la cr√©ation de la matrice de corr√©lation: {str(e)}")

                elif export_option == "Rapport analytique complet":
                    st.markdown("""
                    G√©n√©ration d'un rapport analytique complet au format PDF.
                    """)

                    if st.button("üîç G√©n√©rer le rapport analytique"):
                        try:
                            # Cr√©ation d'un PDF complet avec toutes les analyses
                            pdf = FPDF()

                            # Page de titre
                            pdf.add_page()
                            pdf.set_font("Arial", "B", 24)
                            pdf.cell(0, 20, "RAPPORT ANALYTIQUE COMPLET", 0, 1, "C")
                            pdf.set_font("Arial", "I", 14)
                            pdf.cell(0, 10, f"Analyseur d'Orientation Professionnelle", 0, 1, "C")
                            pdf.set_font("Arial", "", 12)
                            pdf.cell(0, 10, f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}", 0, 1, "C")
                            pdf.cell(0, 10, f"Nombre total d'analyses: {len(stats_df)}", 0, 1, "C")

                            # Image du logo ou autre illustration
                            pdf.image("https://via.placeholder.com/150x150.png?text=Logo", x=80, y=100, w=50)

                            # Sommaire
                            pdf.add_page()
                            pdf.set_font("Arial", "B", 16)
                            pdf.cell(0, 20, "SOMMAIRE", 0, 1)
                            pdf.set_font("Arial", "", 12)
                            pdf.cell(0, 10, "1. Statistiques g√©n√©rales................3", 0, 1)
                            pdf.cell(0, 10, "2. Distribution des scores................4", 0, 1)
                            pdf.cell(0, 10, "3. Analyse des fili√®res..................5", 0, 1)
                            pdf.cell(0, 10, "4. Analyse des carri√®res.................6", 0, 1)
                            pdf.cell(0, 10, "5. M√©tiers recommand√©s...................7", 0, 1)
                            pdf.cell(0, 10, "6. Corr√©lations..........................8", 0, 1)
                            pdf.cell(0, 10, "7. Recommandations.......................9", 0, 1)

                            # Section 1: Statistiques g√©n√©rales
                            pdf.add_page()
                            pdf.set_font("Arial", "B", 16)
                            pdf.cell(0, 20, "1. STATISTIQUES G√âN√âRALES", 0, 1)

                            # M√©triques principales
                            metrics = calculate_metrics()

                            pdf.set_font("Arial", "", 11)
                            pdf.cell(0, 10, f"Nombre total d'analyses: {metrics.get('total_analyses', 0)}", 0, 1)

                            if metrics.get("avg_score") is not None:
                                pdf.cell(0, 10, f"Score moyen de coh√©rence: {metrics.get('avg_score', 0):.1f}/10", 0, 1)
                            else:
                                pdf.cell(0, 10, "Score moyen de coh√©rence: N/A", 0, 1)

                            pdf.cell(0, 10, f"Excellentes orientations: {metrics.get('high_score_percent', 0):.1f}%", 0, 1)

                            pdf.set_font("Arial", "B", 12)
                            pdf.cell(0, 15, "Distribution des scores:", 0, 1)

                            # Distribution simplifi√©e
                            distribution = metrics.get("scores_distribution", {})
                            pdf.set_font("Arial", "", 10)
                            pdf.cell(0, 8, f"‚Ä¢ Scores faibles (0-3): {distribution.get('0-3', 0)} √©tudiants", 0, 1)
                            pdf.cell(0, 8, f"‚Ä¢ Scores moyens (4-6): {distribution.get('4-6', 0)} √©tudiants", 0, 1)
                            pdf.cell(0, 8, f"‚Ä¢ Scores √©lev√©s (7-10): {distribution.get('7-10', 0)} √©tudiants", 0, 1)

                            # Section 2: Distribution des scores (avec image d'histogramme)
                            pdf.add_page()
                            pdf.set_font("Arial", "B", 16)
                            pdf.cell(0, 20, "2. DISTRIBUTION DES SCORES", 0, 1)

                            # Image plac√©e en dur pour simplifier
                            pdf.image("https://via.placeholder.com/500x300.png?text=Histogramme+des+scores", x=10, y=40, w=190)

                            pdf.set_y(150)
                            pdf.set_font("Arial", "", 10)
                            pdf.multi_cell(0, 5, """
                            L'histogramme ci-dessus montre la distribution des scores de coh√©rence.
                            On observe que la majorit√© des √©tudiants se situent dans la zone m√©diane,
                            ce qui indique un besoin d'am√©lioration mod√©r√© pour la plupart des parcours analys√©s.
                            """)

                            # Section 3: Analyse des fili√®res
                            pdf.add_page()
                            pdf.set_font("Arial", "B", 16)
                            pdf.cell(0, 20, "3. ANALYSE DES FILI√àRES", 0, 1)

                            # Top des fili√®res par score moyen
                            if 'filiere' in stats_df.columns and 'score' in stats_df.columns:
                                top_filieres = stats_df.groupby('filiere')['score'].agg(['mean', 'count']).sort_values('mean', ascending=False)

                                pdf.set_font("Arial", "B", 12)
                                pdf.cell(0, 15, "Fili√®res par score moyen de coh√©rence:", 0, 1)

                                # Tableau des fili√®res
                                pdf.set_font("Arial", "B", 10)
                                pdf.cell(80, 10, "Fili√®re", 1, 0, "C")
                                pdf.cell(30, 10, "Score moyen", 1, 0, "C")
                                pdf.cell(30, 10, "Nb √©tudiants", 1, 1, "C")

                                pdf.set_font("Arial", "", 10)
                                for i, (filiere, row) in enumerate(top_filieres.iterrows()):
                                    if i < 10:  # Limite aux 10 premi√®res
                                        pdf.cell(80, 8, str(filiere)[:40], 1, 0)
                                        pdf.cell(30, 8, f"{row['mean']:.1f}", 1, 0, "C")
                                        pdf.cell(30, 8, f"{int(row['count'])}", 1, 1, "C")

                            # Analyses suivantes similaires...
                            # (Section 4 √† 7)

                            # G√©n√©ration du PDF final
                            pdf_data = pdf.output(dest="S").encode("latin-1")

                            st.download_button(
                                "üìä T√©l√©charger le rapport analytique complet",
                                data=pdf_data,
                                file_name=f"rapport_analytique_{datetime.now().strftime('%Y%m%d')}.pdf",
                                mime="application/pdf",
                            )

                            st.success("‚úÖ Rapport analytique g√©n√©r√© avec succ√®s.")
                        except Exception as e:
                            st.error(f"Erreur lors de la g√©n√©ration du rapport analytique: {str(e)}")
        except Exception as e:
            st.error(f"Erreur lors de l'analyse avanc√©e: {str(e)}")


# --- 5. PAGE DE CONFIGURATION API ---
elif menu == "Configuration API":
    st.title("‚öôÔ∏è Configuration de l'API")

    # Statut actuel de l'API
    st.subheader("Statut actuel de l'API")

    api_key = API_KEY
    if api_key:
        # Validation simple
        valid = api_key.startswith("sk-or-") and len(api_key) > 30

        if valid:
            st.success(f"‚úÖ API configur√©e et valide. Cl√©: {api_key[:5]}...{api_key[-4:]}")
        else:
            st.warning(f"‚ö†Ô∏è Probl√®me d√©tect√© avec la cl√© API: format incorrect")
    else:
        st.error("‚õî API non configur√©e. Veuillez entrer votre cl√© API ci-dessous.")

    # Formulaire pour configurer/mettre √† jour la cl√©
    st.subheader("Configurer la cl√© API OpenRouter")

    st.write("""
    Entrez votre cl√© API OpenRouter pour activer les fonctionnalit√©s d'analyse.
    
    Pour obtenir une cl√© API:
    1. Cr√©ez un compte sur [OpenRouter](https://openrouter.ai)
    2. G√©n√©rez une cl√© API dans vos param√®tres de compte
    3. Choisissez le mod√®le DeepSeek Chat comme mod√®le par d√©faut
    """)

    api_key_input = st.text_input(
        "Cl√© API OpenRouter",
        value=api_key,
        type="password",
        placeholder="sk-or-..."
    )

    # Boutons d'action
    col1, col2 = st.columns(2)

    with col1:
        if st.button("Enregistrer la cl√© API", type="primary"):
            if not api_key_input:
                st.error("Aucune cl√© fournie.")
            else:
                # Validation simple
                if api_key_input.startswith("sk-or-") and len(api_key_input) > 30:
                    # Sauvegarde
                    success, message = save_api_key(api_key_input)

                    if success:
                        # Mise √† jour des variables
                        API_KEY = api_key_input

                        # Mise √† jour du placeholder de statut
                        api_status_placeholder.success("‚úÖ API configur√©e")

                        st.success(f"‚úÖ {message}")
                    else:
                        st.error(f"√âchec d'enregistrement: {message}")
                else:
                    st.error(f"Cl√© API invalide: doit commencer par 'sk-or-' et avoir au moins 30 caract√®res")

    with col2:
        if st.button("Tester la connexion API"):
            # V√©rifier si une cl√© est disponible
            test_key = api_key_input if api_key_input else api_key

            if not test_key:
                st.error("Aucune cl√© API disponible pour le test.")
            else:
                with st.spinner("Test de connexion en cours..."):
                    # Sauvegarde temporaire pour test
                    if api_key_input and api_key_input != api_key:
                        os.environ["OPENROUTER_API_KEY"] = api_key_input
                        # Mise √† jour temporaire
                        temp_api_key = API_KEY
                        API_KEY = api_key_input

                    # Test de connexion
                    response = call_api("R√©ponds uniquement 'OK' si tu re√ßois ce message.")

                    # Restauration si n√©cessaire
                    if api_key_input and api_key_input != api_key:
                        API_KEY = temp_api_key

                    if "error" in response:
                        st.error(f"‚ùå {response['error']}")
                    else:
                        st.success(f"‚úÖ Connexion API fonctionnelle: '{response['content']}'")

    # Instructions d√©taill√©es
    with st.expander("Instructions d√©taill√©es"):
        st.markdown("""
        ### Guide d'obtention d'une cl√© API OpenRouter
        
        1. **Cr√©ez un compte sur [OpenRouter](https://openrouter.ai)**
           - Inscrivez-vous avec votre email ou un compte Google
           - Remplissez les informations demand√©es
        
        2. **G√©n√©rez une nouvelle cl√© API**
           - Allez dans *API Keys* dans votre tableau de bord
           - Cliquez sur *Create Key*
           - Donnez un nom √† votre cl√© (ex: "Analyseur d'Orientation")
        
        3. **Configurez vos pr√©f√©rences de mod√®le**
           - S√©lectionnez DeepSeek comme fournisseur pr√©f√©r√©
           - Le mod√®le `deepseek/deepseek-chat-v3-0324` est recommand√©
        
        4. **Copiez la cl√© g√©n√©r√©e**
           - Elle commence toujours par `sk-or-`
           - Collez-la dans le champ ci-dessus et cliquez sur "Enregistrer"
        
        5. **V√©rifiez les cr√©dits disponibles**
           - OpenRouter fournit des cr√©dits gratuits pour tester
           - Vous pouvez √©galement acheter des cr√©dits pour une utilisation intensive
        """)


# --- 6. PAGE √Ä PROPOS ---
elif menu == "√Ä propos":
    st.title("‚ÑπÔ∏è √Ä propos de l'application")

    # Pr√©sentation de l'application
    st.markdown("""
    ## Analyseur d'Orientation Professionnelle
    
    Cette application a √©t√© con√ßue pour aider les conseillers d'orientation et les √©tablissements d'enseignement
    √† √©valuer la coh√©rence entre les fili√®res suivies et les carri√®res envisag√©es par les √©tudiants.
    
    ### Comment √ßa fonctionne
    
    1. L'application analyse chaque √©tudiant individuellement
    2. L'IA √©value la coh√©rence entre la fili√®re suivie et la carri√®re vis√©e
    3. Un score de coh√©rence est attribu√© sur une √©chelle de 0 √† 10
    4. Des recommandations de m√©tiers alternatifs sont propos√©es
    5. Des recommandations concr√®tes sont fournies pour chaque cas
    
    ### L'√©chelle de coh√©rence
    
    - **0-3: R√©orientation n√©cessaire** - √âcart important entre formation et ambition
    - **4-6: √Ä surveiller** - Des ajustements sont recommand√©s
    - **7-10: Excellent choix** - Alignement fort entre formation et ambition
    
    ### Confidentialit√©
    
    Les donn√©es sont trait√©es localement et ne sont pas conserv√©es sur des serveurs externes.
    Seuls les r√©sultats d'analyse sont sauvegard√©s dans un fichier local pour le suivi des performances.
    """)

    # Fonctionnalit√©s ajout√©es
    st.subheader("Nouvelles fonctionnalit√©s (2025)")

    st.markdown("""
    #### Am√©liorations majeures
    
    - **Suggestions de m√©tiers**: Pour chaque √©tudiant, l'IA propose 2 m√©tiers alternatifs qui exploitent les comp√©tences de sa fili√®re
    - **Logique de scoring invers√©e**: Un score √©lev√© indique maintenant une bonne coh√©rence (10 = excellent choix)
    - **Export PDF**: G√©n√©ration de rapports individuels et group√©s en PDF
    - **Analyses avanc√©es**: Visualisations et analyses statistiques pouss√©es des donn√©es
    - **Matrice de compatibilit√©**: Visualisation des meilleures combinaisons fili√®re/carri√®re
    - **Nuages de mots**: Analyse textuelle des fili√®res, carri√®res et m√©tiers recommand√©s
    
    #### Possibilit√©s d'exploitation des donn√©es
    
    - **Cartographie des parcours**: Visualiser les chemins typiques entre fili√®res et carri√®res
    - **Tableau crois√© dynamique**: G√©n√©rer des rapports Excel pour les analyses d'orientation
    - **Analyse de tendances**: Suivre l'√©volution des scores et des recommandations dans le temps
    - **Clustering des √©tudiants**: Regrouper les √©tudiants par profils similaires pour interventions cibl√©es
    - **Pr√©diction de r√©ussite**: Mod√®les statistiques bas√©s sur la coh√©rence fili√®re/carri√®re
    """)

    # Informations techniques
    st.subheader("Informations techniques")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **Technologies utilis√©es:**
        - Streamlit (interface)
        - OpenRouter API (analyse IA)
        - Pandas & NumPy (traitement de donn√©es)
        - Plotly & Matplotlib (visualisations)
        - FPDF (g√©n√©ration de rapports)
        - WordCloud (analyses textuelles)
        """)

    with col2:
        st.markdown("""
        **Mod√®le IA:**
        - DeepSeek Chat V3
        - Format d'analyse structur√©
        - Extraction automatique des scores
        - D√©tection des m√©tiers recommand√©s
        - Recommandations personnalis√©es
        """)

    # Instructions
    st.subheader("Guide d'utilisation")

    st.markdown("""
    1. **Configuration API** - Entrez votre cl√© OpenRouter
    2. **Pr√©paration des donn√©es** - CSV ou Excel avec les colonnes Nom, Fili√®re, Carri√®re
    3. **Analyse** - Importez le fichier et lancez l'analyse
    4. **Interpr√©tation** - Consultez le score, les m√©tiers recommand√©s et les recommandations
    5. **Export** - T√©l√©chargez les r√©sultats en CSV, JSON ou PDF (individuel ou group√©)
    6. **Analyses avanc√©es** - Exploitez les visualisations pour des insights plus profonds
    """)

    # Cas d'utilisation
    st.subheader("Cas d'utilisation")

    st.markdown("""
    - **Universit√©s et √©coles** - Valider les choix d'orientation des √©tudiants et identifier les r√©orientations n√©cessaires
    - **Centres d'orientation** - Offrir des recommandations personnalis√©es bas√©es sur les comp√©tences existantes
    - **Services RH** - Analyser les reconversions professionnelles de collaborateurs
    - **Organismes de formation** - √âvaluer la pertinence des formations par rapport aux objectifs professionnels
    - **Observatoires de l'emploi** - Analyser les tendances des aspirations professionnelles
    """)

    # Contact/Support
    st.markdown("---")
    st.subheader("Support et contact")

    st.info("""
    Pour toute question ou suggestion d'am√©lioration, n'h√©sitez pas √† nous contacter.
    
    Version: 3.0 - Mai 2025
    """)

# Footer global
st.markdown("---")
st.markdown("‚ö° Analyseur d'Orientation Pro - Des m√©tiers sur mesure pour votre avenir - 2025")